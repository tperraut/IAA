{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Le but de ce TP est de mettre en oeuvre le classifieur Bayesien Naif sur les données MNIST. \n",
    "Pour se familiariser avec ces données voir [cette page](https://perso.limsi.fr/Individu/allauzen/webpages/pmwiki.php?n=Cours.Main#toc6). Elles sont également accessible en lecture et en local: \n",
    "\n",
    "    /partage/public/allauzen\n",
    "    \n",
    "Ce corpus rassemble des images (observations) de chiffres isolés et manuscrits ainsi que les classes associées (les labels ou les réponses attendues). Il s'agit donc d'un problème de classification à 10 classes (de 0 à 9). L'objectif est d'assigner le bon chiffre à une image. \n",
    "\n",
    "# Chargement et manipulation des données\n",
    "\n",
    "Reprendre le TP de la semaine dernière afin de charger et manipuler les donner. Vous trouverez ici le strict nécessaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\ttraining examples\n",
      "10000\tvalid examples\n",
      "10000\ttest examples\n"
     ]
    }
   ],
   "source": [
    "import cPickle, gzip, os, math\n",
    "import numpy as np\n",
    "# Load the dataset\n",
    "f = gzip.open(os.getcwd() + \"/mnist.pkl.gz\", 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "\n",
    "print str(len(train_set[0]))+\"\\ttraining examples\"\n",
    "print str(len(valid_set[0]))+\"\\tvalid examples\"\n",
    "print str(len(test_set[0]))+\"\\ttest examples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesien Naif (continu)\n",
    "Les observations sont de nature continue. Chaque image contient 784 pixels dont la valeur est réelle et normalisée entre 0 et 1. On pourrait binariser ce type de données, mais ici nous allons les modéliser ainsi en utilisant des gaussiennes.\n",
    "\n",
    "Une image est un vecteur de caractéristiques contenant 784 composantes. Partons de cette simple représentation. L'hypothèse naïve implique que chaque composante est indépendante des autres. Dans le cas présent, chaque pixel est donc modélisé par une gaussienne. La matrice de covariance est donc diagonale. \n",
    "\n",
    "## TODO\n",
    "Implémenter le Bayesien naïf gaussien: \n",
    "- Calcul des paramètres à partir des données d'apprentissage\n",
    " - Pour chaque classe calculer le vecteur des moyennes\n",
    " - La matrice de covariance (Attention elle est diagonale, on peut se contenter d'un vecteur)\n",
    "- Inférence sur les données de test\n",
    "- Calcul du taux d'erreur sur les données de test (en s'y prenant bien, on doit atteindre les 77%)\n",
    "- Tracer les images \"moyennes\" pour chaque classe ainsi que les variances\n",
    "- Regarder quelques images mal classées par le classifieur\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.98\n"
     ]
    }
   ],
   "source": [
    "# Récupération des images et des labels\n",
    "images = test_set[0]\n",
    "labels = test_set[1]\n",
    "means = dict()\n",
    "variances = dict()\n",
    "ids = list()\n",
    "for i in range(10):\n",
    "    mesImages = images[labels==i] # Les images de la classe i\n",
    "    #Calcul moyen\n",
    "    mean = mesImages.mean(axis=0)\n",
    "    means[i] = mean\n",
    "    var = mesImages.var(axis=0)\n",
    "    variances[i] = var\n",
    "\n",
    "def calculPost(image):\n",
    "    \"\"\"\n",
    "    Proba a posteriori pour toutes les classes\n",
    "    \"\"\"\n",
    "    post = np.zeros([10, 1])\n",
    "    for lbl in range(10):\n",
    "        m = means[lbl]\n",
    "        v = variances[lbl]\n",
    "        non_null = v != 0\n",
    "        s1 = -0.5 * np.log(2 * math.pi * v[non_null])\n",
    "        s2 = -0.5 * np.divide(np.square(image[non_null] - m[non_null]), v[non_null])\n",
    "        post[lbl] = (s1 + s2).sum()\n",
    "    return(post)\n",
    "\n",
    "posts = list()\n",
    "good = 0\n",
    "\n",
    "for i in range(len(images)):\n",
    "    post = calculPost(images[i])\n",
    "    if post.argmax() == labels[i]:\n",
    "        good += 1\n",
    "print good * 100.0 / len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayésien naïf discret\n",
    "\n",
    "Reprendre la même tâche mais en binarizant les images. Pour cela, le modèle de chaque pixel est une binomiale. \n",
    "\n",
    "## TODO\n",
    "- Quels sont les paramètres à estimer pour chaque classe ? \n",
    "- Comment les stockés ? \n",
    "- Implémenter l'estimation, puis l'inférence. (On peut dans un premier temps réutiliser l'implémentation existante de Sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
